{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f3b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24df4d95",
   "metadata": {},
   "source": [
    "## Load and Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cc7454f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "# (int-encoded sentences) based on window size, number of negative samples\n",
    "# and vocabulary size.\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "    # Elements of each training example are appended to these lists.\n",
    "    targets, contexts, labels = [], [], []\n",
    "\n",
    "    # Build the sampling table for `vocab_size` tokens.\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "    # Iterate over all sequences (sentences) in the dataset.\n",
    "    for sequence in tqdm(sequences):\n",
    "\n",
    "        # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "              sequence,\n",
    "              vocabulary_size=vocab_size,\n",
    "              sampling_table=sampling_table,\n",
    "              window_size=window_size,\n",
    "              negative_samples=0)\n",
    "\n",
    "        # Iterate over each positive skip-gram pair to produce training examples\n",
    "        # with a positive context word and negative samples.\n",
    "        for target_word, context_word in positive_skip_grams:\n",
    "            context_class = tf.expand_dims(\n",
    "                  tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                  true_classes=context_class,\n",
    "                  num_true=1,\n",
    "                  num_sampled=num_ns,\n",
    "                  unique=True,\n",
    "                  range_max=vocab_size,\n",
    "                  seed=seed,\n",
    "                  name=\"negative_sampling\")\n",
    "\n",
    "              # Build context and label vectors (for one target word)\n",
    "            context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
    "            label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "            # Append each element from the training example to global lists.\n",
    "            targets.append(target_word)\n",
    "            contexts.append(context)\n",
    "            labels.append(label)\n",
    "\n",
    "    return targets, contexts, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f862fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6e26c5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\William\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bdd40c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "92c348bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, create a custom standardization function to lowercase the text and\n",
    "# remove punctuation.\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "\n",
    "# Define the vocabulary size and the number of words in a sequence.\n",
    "vocab_size = 4096\n",
    "sequence_length = 10\n",
    "\n",
    "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
    "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
    "# same length.\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "696d1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds.batch(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "271d5e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "# Vectorize the data in text_ds.\n",
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "79357e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequences = list(text_vector_ds.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0a19ce43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2b9964ac334af99f943e1bf0c107e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "targets.shape: (65099,)\n",
      "contexts.shape: (65099, 5)\n",
      "labels.shape: (65099, 5)\n",
      "<BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences,\n",
    "    window_size=2,\n",
    "    num_ns=4,\n",
    "    vocab_size=vocab_size,\n",
    "    seed=SEED)\n",
    "\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {targets.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)\n",
    "\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ns = 4\n",
    "class Word2Vec(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.target_embedding = layers.Embedding(vocab_size,\n",
    "                                          embedding_dim,\n",
    "                                          input_length=1,\n",
    "                                          name=\"w2v_embedding\")\n",
    "        self.context_embedding = layers.Embedding(vocab_size,\n",
    "                                           embedding_dim,\n",
    "                                           input_length=num_ns+1)\n",
    "\n",
    "    def call(self, pair):\n",
    "        target, context = pair\n",
    "        # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
    "        # context: (batch, context)\n",
    "        if len(target.shape) == 2:\n",
    "            target = tf.squeeze(target, axis=1)\n",
    "        # target: (batch,)\n",
    "        word_emb = self.target_embedding(target)\n",
    "        # word_emb: (batch, embed)\n",
    "        context_emb = self.context_embedding(context)\n",
    "        # context_emb: (batch, context, embed)\n",
    "        dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "        # dots: (batch, context)\n",
    "        return dots\n",
    "def custom_loss(x_logit, y_true):\n",
    "    return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ca16beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e2f9b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "62ef7bd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 1.6082 - accuracy: 0.2343\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 1.5890 - accuracy: 0.5527\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 1.5417 - accuracy: 0.5894\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 1.4599 - accuracy: 0.5661\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 1.3624 - accuracy: 0.5754\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 1.2653 - accuracy: 0.6050\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 1.1742 - accuracy: 0.6408\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 5s 83ms/step - loss: 1.0893 - accuracy: 0.6755\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 1.0103 - accuracy: 0.7095\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 5s 82ms/step - loss: 0.9370 - accuracy: 0.7392\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 5s 82ms/step - loss: 0.8692 - accuracy: 0.7655\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 0.8067 - accuracy: 0.7882\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 0.7493 - accuracy: 0.8088\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 0.6967 - accuracy: 0.8259\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.6486 - accuracy: 0.8402\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.6048 - accuracy: 0.8535\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 0.5649 - accuracy: 0.8646\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 0.5286 - accuracy: 0.8755\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.4956 - accuracy: 0.8851\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.4656 - accuracy: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1adf9afcf40>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faff88c",
   "metadata": {},
   "source": [
    "## Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a1e4c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "44dda744",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "for idx, word in enumerate(vocab):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "        \n",
    "    embeddings[word] = weights[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b593d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_dis(word1, word2):\n",
    "    \"\"\"\n",
    "    returns cosine similiarity, disimilarity which is given by mean squared error.\n",
    "    \"\"\"\n",
    "    vec1 = embeddings[word1]\n",
    "    vec2 = embeddings[word2]\n",
    "\n",
    "    cosine = np.dot(vec1,vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2))\n",
    "    return cosine, np.abs(vec1-vec2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dce59650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09736582, 0.23770557)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_dis('this', 'he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ad0d3652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13859883, 0.2217257)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_dis('this', 'that')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
